\chapter{Fine-tuning Job Specifications}

As UA-HPC system-administrators, we often observe that the UA-HPC resources are not optimally (or wisely) used. For example, we regularly notice that several cores on a computing node are not utilized, due to the fact that one sequential program uses only one core on the node. Or users run I/O intensive applications on nodes with `slow' network connections.

Users often tend to run their jobs without specifying specific PBS Job parameters.  As such, their job will automatically use the default parameters, which are not necessarily (or rarely) the optimal ones.  This can slow down the runtime of your application, but also block UA-HPC resources for other users.

Specifying the `optimal' Job Parameters requires some knowledge of your application (e.g., how many parallel threads does my application uses, is there a lot of inter-process communication, how much memory does my application need) and also some knowledge about the UA-HPC infrastructure (e.g., what kind of multi-core processors are available, which nodes have infiniband).

There are plenty of monitoring tools on Linux available to the user, which are useful to analyze your individual application. The UA-HPC environment as a whole often requires different techniques, metrics and time goals, which are not discussed here. We will focus on tools that can help to optimize your Job Specifications.

Determining the optimal computer resource specifications can be broken down into different parts. The first is actually determining which metrics are needed and then collecting that data from the hosts. Some of the most commonly tracked metrics are CPU usage, memory consumption, network bandwidth, and disk I/O stats. These provide different indications of how well a system is performing, and may indicate where there are potential problems or performance bottlenecks. Once the data have actually been acquired, the second task is analyzing the data and adapting your PBS Job Specifications.

Another different task is to monitor the behavior an application at runtime and detect anomalies or unexpected behavior. Linux provides a large number of utilities to monitor the performance of its components.

This chapter shows you how to measure:

\begin{enumerate}
\item  Walltime
\item  Memory usage
\item  CPU usage
\item  Disk (storage) needs
\item  Network bottlenecks
\end{enumerate}

First, we allocate a compute node and move to our relevant directory:
\begin{prompt}
$ %\textbf{qsub -I}%
$ %\textbf{cd \~/examples/Chapter11\_TuneJobs}%
\end{prompt}

\section{Specifying Walltime}

One of the most important and also easiest parameters to measure is the duration of your program. This information is needed to specify the \textit{walltime}.

The \textit{time} utility \textbf{executes} and \textbf{times} your application.  You can just add the time command in front of your normal command line, including your command line options. After your executable has finished, \textit{time} writes the total time elapsed, the time consumed by system overhead, and the time used to execute your executable to the standard error stream.  The calculated times are reported in seconds.


Test the time command:
\begin{prompt}
$ %\textbf{time sleep 75}%
real 1m15.005s
user 0m0.001s
sys 0m0.002s
\end{prompt}

It is a good practice to correctly estimate and specify the runtime (duration) of an application. Of course, a margin of 10\% to 20\% can be taken to be on the safe side.

It is also wise to check the walltime on different compute nodes or to select the ''slowest'' compute node for your walltime tests. Your estimate should appropriate in case your application will run on the ``slowest'' (oldest) compute nodes.

The walltime can be specified in a job scripts as:
\begin{prog}
\#PBS --l Walltime=3:12:00:00
\end{prog}

or on the command line
\begin{prog}
-l walltime=3:00:00:00
\end{prog}

It is recommended to always specify the walltime for a job.

\section{Specifying memory requirements}

In many situations, it is useful to monitor the amount of memory an application is using. You need this information to determine the characteristics of the required compute node, where that application should run on.  Estimating the amount of memory an application will use during execution is often non-trivial, especially when one uses third-party software.

The ``eat\_mem'' application just consumes and then releases memory, for the purpose of this test. It has one parameter, the amount of Gigabits of memory which needs to be allocated.

First compile the program on your machine and then test it for 1 Gb:
\begin{prompt}
$ %\textbf{gcc -o eat\_mem eat\_mem.c}%
$ %\textbf{./eat\_mem 1}%
Consuming 1 Gigabit of memory.
\end{prompt}


\subsection{Available Memory on the machine}

The first point is to be aware of the available free memory in your computer. The ``\textit{free}'' command displays the total amount of free and used physical and swap memory in the system, as well as the buffers used by the kernel. We also use the options ``-m'' to see the results expressed in Mega-Bytes and the ``-t'' option to get totals.
\begin{prompt}
$ %\textbf{free -m -t}%
                total   used   free  shared  buffers  cached
Mem:            16049   4772  11277       0      107     161
-/+ buffers/cache:      4503  11546
Swap:           16002   4185  11816
Total:          32052   8957  23094
\end{prompt}

Important is to note the total amount of memory available in the machine (i.e.,  16Gb in this example) and the amount of used and free memory (i.e. 4,7 Gb is used and another 11,2 Gb is free here).

It is not a good practice to use Swap-space for your computational applications. A lot of ``swapping'' can increase the execution time of your application tremendously.

\subsection{Checking the memory consumption}

The ``Monitor'' tool monitors applications in terms of memory and CPU usage, as well as the size of temporary files. Note that currently only single node jobs are supported, MPI support may be added in a future release.

To start using monitor, first load the appropriate module. Then we study the ``eat\_mem.c'' program and compile it:
\begin{prompt}
$ %\textbf{module load monitor}%
$ %\textbf{cat eat\_mem.c}%
$ %\textbf{gcc --o eat\_mem eat\_mem.c}%
\end{prompt}

Starting a program to monitor is very straightforward; you just add the ``monitor'' command before the regular command line.
\begin{prompt}
$ %\textbf{monitor ./eat\_mem 3}%
time (s) size (kb) \%mem \%cpu
Consuming 3 Gigabit of memory.
5  252900 1.4 0.6
10  498592 2.9 0.3
15  743256 4.4 0.3
20  988948 5.9 0.3
25  1233612 7.4 0.3
30  1479304 8.9 0.2
35  1723968 10.4 0.2
40  1969660 11.9 0.2
45  2214324 13.4 0.2
50  2460016 14.9 0.2
55  2704680 16.4 0.2
60  2950372 17.9 0.2
65  3167280 19.2 0.2
70  3167280 19.2 0.2
75  9264  0 0.5
80  9264  0 0.4
\end{prompt}

Whereby:

\begin{enumerate}
\item  The first column shows you the elapsed time in seconds. By default, all values will be displayed every 5 seconds.
\item  The second column shows you the used memory in kb. We note that the memory slowly increases up to 3 Gb (=  kb), and is released again.
\item  The third column shows the memory utilization, expressed in percentages of the full available memory.  At full memory consumption, 19,2\% of the memory was being used by our application. With the \textit{``free''} command, we have previously seen that we had a node of 16Gb in this example. 3Gb is indeed more or less 19,2\% of the full available memory.
\item  The fourth column shows you the CPU utilization, expressed in percentages of a full CPU load. As there are no computations done in our exercise, the value remains very low (i.e. 0.2\%).
\end{enumerate}

Monitor will write the CPU usage and memory consumption of simulation to standard error.

This is the rate at which monitor samples the program's metrics. Since monitor's output may interfere with that of the program to monitor, it is often convenient to use a log file. The latter can be specified as follows:
\begin{prompt}
$ %\textbf{monitor -l test1.log eat\_mem 2}%
Consuming 2 Gigabit of memory.
$ %\textbf{cat test1.log}%
\end{prompt}

For long running programs, it may be convenient to limit the output to, e.g., the last minute of the programs execution. Since monitor provides metrics every 5 seconds, this implies we want to limit the output to the last 12 values to cover a minute:

\begin{prompt}
$ %\textbf{monitor -l test2.log -n 12 eat\_mem 4}%
Consuming 4 Gigabit of memory.
\end{prompt}

Note that this option is only available when monitor writes its metrics to a log file, not when standard error is used.

The interval at which monitor will show the metrics can be modified by specifying delta, the sample rate:
\begin{prompt}
$ %\textbf{monitor -d 1 ./eat\_mem}%
Consuming 3 Gigabit of memory.
\end{prompt}

Monitor will now print the program's metrics every second. Note that the minimum delta value is 1 second.

Alternative options to monitor the memory consumption are the ``\textit{top}'' or the ``\textit{htop}'' command.

\begin{enumerate}
\item  \textbf{top} provides an ongoing look at processor activity in real time. It displays a listing of the most CPU-intensive tasks on the system, and can provide an interactive interface for manipulating processes. It can sort the tasks by memory usage, CPU usage and runtime.
\item  \textbf{htop} is  similar to top, but shows the CPU-utilization for all the CPUs in the machine and allows to scroll the list vertically and horizontally to see all processes and their full command lines.
\end{enumerate}

\begin{prompt}
$ %\textbf{top}%
$ %\textbf{htop}%
\end{prompt}

\subsection{Setting the memory parameter}

Once you gathered a good idea of the overall memory consumption of your application, you can define it in your job script.  It is wise to foresee a margin of about 10\%.

\underbar{Sequential or single-node applications: }

The maximum amount of physical memory used by the job can be specified in a job script as:
\begin{prog}
\#PBS --l mem=4gb
\end{prog}

or on the command line
\begin{prog}
-l mem=4gb
\end{prog}

This setting is ignored if the number of nodes is not 1.

\underbar{Parallel or multi-node applications:}

When you are running a parallel application over multiple cores, you can also specify the memory requirements per processor (pmem). This directive specifies the maximum amount of physical memory used by any process in the job.

For example, if the job would run four processes and each would use up to 2 GB (gigabytes) of memory, then the directive would read:

\begin{prog}
 \#PBS -l pmem=2gb
\end{prog}

or on the command line
\begin{prog}
-l pmem=2gb
\end{prog}

In this example, you request 8Gb of memory in total on the node.

\section{Specifying processors requirements}

Users are encouraged to fully utilize all the available cores on a certain compute node. Once the required numbers of cores and nodes are decently specified, it is also good practice to monitor the CPU utilization on these cores and to make sure that all the assigned nodes are working at full load.

\subsection{Number of processors}

The number of core and nodes that a user shall request fully depends on the architecture of the application. The developer designs his application with a strategy for parallelization in mind. The application can be designed for a certain fixed number or for a configurable number of nodes and cores. It is wise to target a specific set of compute nodes (e.g., Westmere, Harpertown) for your computing work and then to configure your software to nicely fill up all processors on these compute nodes.

The \textit{/proc/cpuinfo} stores info about your CPU architecture like number of CPUs, threads, cores, information about CPU caches, CPU family, model and much more.  So, if you want to detect how many cores are available on a specific machine:

\begin{prompt}
$ %\textbf{less /proc/cpuinfo}%
processor       : 0
vendor\_id       : GenuineIntel
cpu family      : 6
model           : 23
model name      : Intel(R) Xeon(R) CPU  E5420  @ 2.50GHz
stepping        : 10
cpu MHz         : 2500.088
cache size      : 6144 KB
\dots
\end{prompt}

Or if you want to see it in a more readable format, execute:
\begin{prompt}
$ %\textbf{grep processor /proc/cpuinfo}%
processor : 0
processor : 1
processor : 2
processor : 3
processor : 4
processor : 5
processor : 6
processor : 7
\end{prompt}


In order to specify the number of nodes and the number of processors per node in your job script, use:
\begin{prog}
\#PBS -l nodes=N:ppn=M
\end{prog}
or with equivalent parameters on the command line
\begin{prog}
-l nodes=N:ppn=M
\end{prog}

In this example, you request 8Gb of memory in total on the node.

This specifies the number of nodes (nodes=N) and the number of processors per node (ppn=M) that the job should use. PBS treats a processor core as a processor, so a system with eight cores per compute node can have ppn=8 as its maximum ppn request. Note that unless a job has some inherent parallelism of its own through something like MPI or OpenMP, requesting more than a single processor on a single node is usually wasteful and can impact the job start time.

\subsection{Monitoring the CPU-utilization}

The previously used ``monitor'' tool also shows the overall CPU-load. The ``eat\_cpu'' program performs a multiplication of 2 randomly filled a 1500x1500 matrices and is just written to consumes a lot of ``\textit{cpu}''.

We first load the monitor modules, study the ``eat\_cpu.c'' program and compile it:
\begin{prompt}
$ %\textbf{module load monitor}%
$ %\textbf{cat eat\_cpu.c}%
$ %\textbf{gcc --o eat\_cpu eat\_cpu.c}%
\end{prompt}

And then start to monitor the \textit{eat\_cpu} program:
\begin{prompt}
$ %\textbf{monitor -d 1 ./eat\_cpu}%
time  (s) size (kb) \%mem \%cpu
1  52852  0.3 100
2  52852  0.3 100
3  52852  0.3 100
4  52852  0.3 100
5  52852  0.3  99
6  52852  0.3 100
7  52852  0.3 100
8  52852  0.3 100
\end{prompt}

We notice that it the program keeps its CPU nicely busy at 100\%.

Some processes spawn one or more sub-processes. In that case, the metrics shown by monitor are aggregated over the process and all of its sub-processes (recursively). The reported CPU usage is the sum of all these processes, and can thus exceed 100 \%.

Some (well, since this is a UA-HPC cluster, we hope most) programs use more than one core to perform their computations. Hence, it should not come as a surprise that the CPU usage is reported as larger than 100 \%. When programs of this type are running on a computer with n cores, the CPU usage can go up to n x 100 \%.

This could also be monitored with the \textbf{\textit{htop}} command:
\begin{prompt}
$ %\textbf{htop}%
  1  \textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar 100.0\%\textbf{]}
  2  \textbf{[  }                                                       \textbf{ 0.0\%]}
  3  \textbf{[}\textbar \textbf{   }                                                      \textbf{0.6\%]}
  4  \textbf{[  }                                                \textbf{        0.0\%]}
  5  \textbf{[ }                   \textbf{          }                           \textbf{ 0.0\%]}
  6  \textbf{[    }                                                     \textbf{ 0.0\%]}
  7  \textbf{[}\textbar \textbar \textbf{    }                                                   \textbf{ 1.3\%]}
  8  \textbf{[}\textbar \textbar \textbar \textbf{   }                                                    \textbf{2.6\%]}
  Mem\textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar                               \textbf{4563/16049MB]}
  Swp\textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar                                  \textbf{4183/16002MB]}

  PID USER     PRI  NI  VIRT   RES   SHR S CPU\% MEM\%   TIME+  Command
14423 vsc20167  25   0 56380 53076   280 R 99.0  0.3  0:12.79 ./eat\_cpu
24307 vsc20167  15   0 66792  1528   956 R  3.0  0.0  0:34.48 htop
 4431 \textbf{root     }  0 -20 5540M 4181M 75032 S  0.0 26.1 \textbf{ 5h}27:02 /usr/lpp/mmfs/bin//mmfsd

\dots
\end{prompt}

The advantage of htop is that it shows you the cpu utilization for all processors as well as the details per application.  A nice exercise is to start 4 instances of the ``cpu\_eat'' program in 4 different terminals, and inspect the cpu utilization per processor with monitor and htop.

If \textbf{\textit{htop}} reports that your program is taking 75\% CPU on a certain processor, it means that 75\% of the samples taken by top found your process active on the CPU. The rest of the time your application was in a wait. (It is important to remember that a CPU is a discrete state machine. It really can be at only 100\%, executing an instruction, or at 0\%, waiting for something to do. There is no such thing as using 45\% of a CPU. The CPU percentage is a function of time.) However, it is likely that your application's rest periods include waiting to be dispatched on a CPU and not on external devices. That part of the wait percentage is then very relevant to understanding your overall CPU usage pattern.

\subsection{Fine-tuning your executable and/or job-script}

It is good practice to perform a number of runtime stress tests, and to check the CPU utilization of your nodes. We (and all other users of the UA=HPC) would appreciate that you use the maximum of the CPU resources that are assigned to you and make sure that there are no CPU's in your node who are not utilized without reasons.

But how can you maximize?

\begin{enumerate}
\item  Configure your software. (e.g., to exactly use the available amount of processors in a node)
\item  Develop your parallel program in a smart way.
\item  Demand a specific type of compute node (e.g., Harpertown, Westmere), which have a specific number of cores.
\item  Correct your request for CPU's in your job-script.
\end{enumerate}

\section{The system load}

On top of the CPU utilization, it is also important to check the \textbf{system load}.  The system \textbf{load} is a measure of the amount of computational work that a computer system performs.

The system load is the number of applications running or waiting to run on the compute node.  In a system with for example four CPUs, a load average of 3.61 would indicate that there were, on average, 3.61 processes ready to run, and each one could be scheduled into a CPU.

The load averages differ from CPU percentage in two significant ways:

\begin{enumerate}
\item  ``\textit{load averages}'' measure the trend in CPU utilization (and not only an instantaneous snapshot, as does CPU percentage); and
\item  ``\textit{load averages}'' include all demand for the CPU (and not only how much was active at the time of measurement).
\end{enumerate}

\subsection{Optimal load}

What is the ``\textbf{optimal load''} rule of thumb?

The load averages tell us whether our physical CPUs are over- or under-utilized. The \textbf{point of perfect utilization}, meaning that the CPUs are always busy and, yet, no process ever waits for one, is \textbf{the average matching the number of CPUs}.  Your load should not exceed the number of cores available.  E.g., if there are four CPUs on a machine and the reported one-minute load average is 4.00, the machine has been utilizing its processors perfectly for the last 60 seconds. The "100\% utilization" mark is 1.00 on a single-core system, 2.00, on a dual-core, 4.00 on a quad-core, etc. The optimal load shall be between 0.7 and 1.0 per processor.

In general, the intuitive idea of load averages is the higher they rise above the number of processors, the more demand there is for the CPUs, and the lower they fall below the number of processors, the more untapped CPU capacity there is.

\textit{Load averages} do not include any processes or threads waiting on I/O, networking, databases or anything else not demanding the CPU. It narrowly focuses on what is actively demanding CPU time. This means that the optimal \textit{number of applications} running on a system at the same time, might be more than one per processor.

The ``\textbf{optimal number of applications''} running on one machine at the same time depends on the type of the applications that you are running.

\begin{enumerate}
\item  When you are running \textbf{computational intensive applications}, one application per processor will generate the optimal load.
\item  For \textbf{IO intensive applications} (e.g., applications with perform a lot of disk-IO), a higher number of applications can generate the optimal load. While some applications are reading or writing data on disks, the processors can serve other applications.
\end{enumerate}

The optimal number of applications on a machine could be empirically calculated by performing a number of stress tests, whilst checking the highest throughput. There is however no manner in the UA-HPC at the moment to specify the maximum number of applications that shall run per core dynamically.  The UA-HPC scheduler will not launch more than one process per core.

The manner how the cores are spread out over CPUs does not matter for what regards the load. Two quad-cores perform similar to four dual-cores, and again perform similar to eight single-cores. It's all eight cores for these purposes.

\subsection{Monitoring the load}

The \textbf{load average} represents the average system load over a period of time. It conventionally appears in the form of three numbers, which represent the system load during the last \textbf{one}-, \textbf{five}-, and \textbf{fifteen}-minute periods.

The \textbf{uptime} command will show us the average load
\begin{prompt}
$ %\textbf{uptime}%
10:14:05 up 86 days, 12:01, 11 users,
                                load average: 0.60, 0.41, 0.41
\end{prompt}


Now, start a few instances of the ``\textit{eat\_cpu}'' program in the background, and check the effect on the load again:
\begin{prompt}
$ %\textbf{./eat\_cpu\&}%
$ %\textbf{./eat\_cpu\&}%
$ %\textbf{./eat\_cpu\&}%
$ %\textbf{uptime}%
10:14:42 up 86 days, 12:02, 11 users, load average: 2.60, 0.93, 0.58
\end{prompt}

You can also read it in the \textbf{htop} command:
\begin{prompt}
$\textbf{ htop}
1  \textbf{[}\textbar \textbar \textbar \textbf{   }                                             \textbf{ 2.6\%]}     Tasks: \textbf{318}, \textbf{176} thr; \textbf{2} running
2  \textbf{[}\textbar \textbar                                                  \textbf{ 1.9\%]}     Load average: \textbf{1.91 0.93} \textbf{0.56 }
3  \textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbf{     }                                    \textbf{16.2\%]}     Uptime: \textbf{82 days, 18:10:17}
\end{prompt}

\subsection{Fine-tuning your executable and/or job-script}

It is good practice to perform a number of runtime stress tests, and to check the system load of your nodes. We (and all other users of the UA=HPC) would appreciate that you use the maximum of the CPU resources that are assigned to you and make sure that there are no CPU's in your node who are not utilized without reasons.

But how can you maximize?

\begin{enumerate}
\item  Profile your software to improve its performance.
\item  Configure your software (e.g., to exactly use the available amount of processors in a node).
\item  Develop your parallel program in a smart way, so that it fully utilizes the available processors.
\item  Demand a specific type of compute node (e.g., Harpertown, Westmere), which have a specific number of cores.
\item  Correct your request for CPU's in your job-script.
\end{enumerate}

And then check again.

\section{Checking File sizes \& Disk IO}

\subsection{Monitoring File sizes during execution}

Some programs generate intermediate or output files, the size of which may also be a useful metric.

Remember that your available disk space on the UA-HPC online storage is limited, and that you 3 environment variables which point to these directories available (i.e. \textit{\$VSC\_DATA}, \textit{\$VSC\_SCRATCH} and \textit{\$VSC\_DATA}). On top of those, you can also access some temporary storage (i.e., the /tmp directory) on the compute node, which is defined by the \textit{\$VSC\_SCRATCH\_LOCAL} environment variable.

We first load the monitor modules, study the ``eat\_disk.c'' program and compile it:
\begin{prompt}
$ %\textbf{module load monitor}%
$ %\textbf{cat eat\_disk.c}%
$ %\textbf{gcc -o eat\_disk eat\_disk.c}%
\end{prompt}

The \textit{monitor} tool provides an option (-f) to display the size of one or more files:
\begin{prompt}
$ %\textbf{monitor -f \$VSC\_SCRATCH/test.txt ./eat\_disk}%
time (s) size (kb) \%mem \%cpu /scratch/antwerpen/201/vsc20167/test.txt
5  1276  0 38.6 168820736
10  1276  0 24.8 238026752
15  1276  0 22.8 318767104
20  1276  0 25 456130560
25  1276  0 26.9 614465536
30  1276  0 27.7 760217600
\dots
\end{prompt}

Here, the size of the file `\textit{test.txt}' in directory \$VSC\_SCRATCH will be monitored. Files can be specified by absolute as well as relative path, and multiple files are separated by ','.

It is important to be aware of the sizes of the file that will be generated, as the available disk space for each user is limited.  We refer to Chapter 6.5 on ``Quota's'' to check your quota and tools to find which files consumed the ``quota''.

Several actions can be taken, to avoid storage problems:

\begin{enumerate}
\item  Be aware of all the files that are generated by your program. Also check out the hidden files.
\item  Check your quota consumption regularly.
\item  Clean up your files regularly.
\item  First work (i.e. read and write) with your big files in the local /tmp directory. Once finished, you can move your files once to the VSC\_DATA directories.
\item  Make sure your programs clean up their temporary files after execution.
\item  Move your output results to your own computer regularly.
\item  Anyone can request more disk space to the UA-HPC staff, but you will have to duly justify your request.
\end{enumerate}

\subsection{Monitoring Disk IO}

If your Linux system gets slow down due to heavy disk I/O activities, you probably want to know which processes or users (in case of multi-user systems) are the culprit for such activities.

If you want to monitor disk I/O activities of individual Linux processes, you can try \textit{iotop}. This tool shows a sorted list of the most I/O intensive processes in real time via a \textit{top}-like interface.

\begin{prompt}
$ %\textbf{iotop}%
\end{prompt}

Running \textit{iotop} without any argument like above shows a list of \textit{all} existing processes regardless of their disk I/O activities. If you want \textit{iotop} to only show processes that are actually doing disk I/O, run the following instead.
\begin{prompt}
$ %\textbf{iotop --o}%
\end{prompt}

\underbar{Remark}: The iotop tool is not available on all compute nodes.

If you are interested in monitoring disk read/write rates of individual disks, you can use \textit{iostat}.
\begin{prompt}
$ %\textbf{iostat}%
Linux 2.6.18-164.6.1.el5 (r1e2cn12)  11/04/2013

avg-cpu:  \%user   \%nice \%system \%iowait  \%steal   \%idle
          69.33    0.00   13.02    0.08    0.00   17.57

Device:    tps   Blk\_read/s   Blk\_wrtn/s   Blk\_read   Blk\_wrtn
sda       3.05         0.27       450.05    2037907 3366173632
sda1      3.05         0.27       450.05    2036637 3366173632
sda2      0.00         0.00         0.00        851          0
\end{prompt}


\section{Specifying network requirements}

The user can examine his network activities with the htop command. When your processors are 100\% busy, but you see a lot of red bars (\textbar \textbar \textbar \textbar ) and only limited green bars (\textbar \textbar \textbar \textbar ) in the htop screen, it is mostly an indication that they loose a lot of time with inter-process communication.

Whenever your application utilizes a lot of inter-process communication (as is the case in most parallel programs), we strongly recommend to request nodes with an ``infiniband'' network. The Infiniband is a specialized high bandwidth, low latency network that enables large parallel jobs to run as efficiently as possible.

The parameter to add in your job-script would be:
\begin{prog}
\#PBS --l ib
\end{prog}

If for some other reasons, a user is fine with the Gigabit Ethernet network, he can specify:
\begin{prog}
\#PBS --l gbe
\end{prog}

\section{Some more tips on the Monitor tool}

\subsection{Command Lines arguments}

Many programs, e.g., matlab, take command line options. To make sure these do not interfere with those of monitor and vice versa, the program can for instance be started in the following way:
\begin{prompt}
$ %\textbf{monitor -delta 60 -- matlab -nojvm -nodisplay computation.m}%
\end{prompt}

The use of '--' will ensure that monitor does not get confused by matlab's '-nojvm' and '-nodisplay' options.

\subsection{Exit Code}

Monitor will propagate the exit code of the program it is watching. Suppose the latter ends normally, then monitor's exit code will be 0. On the other hand, when the program terminates abnormally with a non-zero exit code, e.g., 3, then this will be monitor's exit code as well.

When monitor has to terminate in an abnormal state, for instance if it can't create the log file, its exit code will be 65. If this interferes with an exit code of the program to be monitored, it can be modified by setting the environment variable MONITOR\_EXIT\_ERROR to a more suitable value.

\subsection{Monitoring a running process}

It is also possible to "attach" monitor to a program or process that is already running. One simply determines the relevant process ID using the ps command, e.g., 18749, and starts monitor:
\begin{prompt}
$ %\textbf{monitor -p 18749}%
\end{prompt}

Note that this feature can be (ab)used to monitor specific sub-processes.

