
Jobs are submitted and executed using job scripts. In our case **run.sh** can be used as a (very minimal) job script.

A job script is a shell script, a text file that specifies the resources, 
the software that is used (via `module load` statements), 
and the steps that should be executed to run the calculation.

Our job script looks like this:

<center>-- run.sh --</center>

```bash
#!/bin/bash

module load TensorFlow/2.11.0-foss-2022a

python tensorflow_mnist.py

```
<sub>As you can see this job script will run the Python script named **tensorflow_mnist.py**.</sub>


The jobs you submit are per default executed on **cluser/{{defaultcluster}}**, you can swap to another cluster by issuing the following command.

```shell
module swap cluster/{{othercluster}}
```

!!! Tip
    
    When submitting jobs with limited amount of resources, it is recommended to use the debug/interactive cluster[1]: `donphan`. 


    To get a list of all clusters and their hardware, see <https://www.ugent.be/hpc/en/infrastructure>.


This job script can now be submitted to the cluster's job system for execution, using the qsub (**q**ueue **sub**mit) command:

```shell
$ qsub run.sh
{{jobid}}
```

This command returns a job identifier (*{{jobid}}*) on the HPC cluster. This is a unique identifier for the job which can be used to monitor and manage your job.

!!! Warning "Make sure you understand what the `module` command does"
 
    Note that the module commands only modify environment variables. For instance, running `module swap cluster/{{othercluster}}` will update your shell environment so that `qsub` submits a job to the `{{othercluster}}` cluster, 
    but our active shell session is still running on the login node.
    
    It is important to understand that while `module` commands affect your session environment, they do ***not*** change where the commands your are running are being executed: they will still be run on the login node you are on.
    
    When you submit a job script however, the commands ***in*** the job script will be run on a workernode of the cluster the job was submitted to (like `{{othercluster}}`).

For detailed information about `module` commands, read the running batch jobs[2] chapter.

[1]: interactive_debug.md#interactive-and-debug-cluster
[2]: running_batch_jobs.md

reference: docs.hpc.ugent.be/getting_started_copy/#submitting-a-job
