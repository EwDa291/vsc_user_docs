\chapter{Introduction}
\label{ch:ch01_introduction}
\section{Purpose}
\label{sec:Purpose}

\strong{HPC systems} are notorious for operating at a small fraction of their peak performance, and the ongoing migration to multi-core and multi-socket compute nodes further complicates performance optimization.

The previously available \strong{performance optimization tools} require considerable effort to learn and use. To enable wide access to performance optimization, TACC and its technology insertion partners have developed PerfExpert, a tool that combines a simple user interface with a sophisticated analysis engine to:

\begin{enumerate}
  \item  \strong{Detect} and \strong{diagnosis} the causes for typical core, socket, and node-level performance bottlenecks in procedures and loops of an application;
  \item  Apply \strong{pattern-based software transformations} on the application source code to enhance performance on identified bottlenecks;
  \item  Provide \strong{performance analysis report} and \strong{suggestions for remediation }for application's performance bottlenecks, which compilers are unable to apply automatically.
\end{enumerate}

PerfExpert was developed at the Texas Advanced Computing Center (\strong{TACC}) as an easy to use tool for diagnosing the performance of scientific applications. While most profiler tools give a sense of \strong{where} performance bottlenecks and hotspots occur, PerfExpert aims to explain \strong{why}, even going so far as to provide relevant code modification suggestions that could improve performance.

\section{Under the hood}
\label{sec:Under_the_hood}

The performance of scientific computing applications is heavily influenced by memory access and floating-point unit (FPU) utilization. Many modern CPUs contain a variety of hardware performance counter events that are useful in diagnosing resource utilization and access patterns. These counters capture events such as L1 and L2 cache misses, branch instruction mispredictions, and execution of floating point instructions. PerfExpert collects these statistics and attempts to correlate them with the code being analyzed. Thus, individual functions or even separate loop nests can be characterized in terms of the kinds of CPU instructions and memory accesses they produce.

PerfExpert is built on top of two profiling tools that provide access to the \strong{timing }and\strong{ hardware performance counter events figures}: PAPI and HPCToolkit.

\begin{enumerate}
  \item  \strong{PAPI} is a library that provides access to CPU hardware performance counter events. Because the implementation of performance counters differs across CPU manufacturers and models, PAPI provides an abstracted interface that allows the user to retrieve the desired information regardless of the underlying OS or CPU architecture.
  \item  \strong{HPCToolkit} is a profiling tool that uses periodic \emph{statistical sampling} to read the performance counter events (using PAPI) and call structure of any executable compiled with debugging symbols. This approach is important because it can be run against executables compiled with full optimization.
\end{enumerate}

By combining the statistical sampling of program execution from HPCToolkit with the hardware performance counter events values from PAPI, an accurate correlation between CPU instructions, cache accesses, program structure, and execution time can be assembled. PerfExpert orchestrates the profiling process to provide easy to use reports and suggestions for improvement.

\strong{Summarized:} PerfExpert aims to be an Easy-to-Use Performance Diagnosis Tool for HPC Applications.

\section{Environment Configuration}
\label{sec:Environment_Configuration}

First, connect to \hpcname of the \university:
\begin{prompt}
%\shellcmd{ssh \userid{}@\loginnode}%
\end{prompt}

You can now create your own copy of the examples by copying the examples for this tutorial to your home directory.
\begin{prompt}
%\shellcmd{cp --r \tutorialdir/perfexpert/examples ~/}%
\end{prompt}

The runs with PerfExpert should be made using a data set size for each compute node which is representative to a full production runs but for which execution time is not more than about ten or fifteen minutes since PerfExpert will run your application multiple times (actually, three times on Stampede) with different performance counters enabled.

For that reason, before you run PerfExpert for your own purpose later, you should either request interactive access to computational resources (compute node), or modify the job script that you use to run your application and specify a running time that is about 3 (for Stampede, Hopper) or 6 (for Lonestar) times the normal running time of the program.

For the exercises in this tutorial, we request interactive access on a compute node to work on for e.g., 2 hours:

\iftacc
\begin{prompt}
%\shellcmd{idev -t 2:00:00}%
\end{prompt}
\fi
\ifvsc
\begin{prompt}
%\shellcmd{qsub -l walltime=2:00:00 -l nodes=1:ppn=4 -I}%
\end{prompt}
\fi

PerfExpert depends on HPCToolkit, and PAPI library, thus it requires the papi, hpctoolkit, and perfexpert modules to be loaded. The "module help" command provides additional information.

And load the appropriate modules:
\iftacc
\begin{prompt}
%\shellcmd{module load papi hpctoolkit perfexpert}%
\end{prompt}
\fi
\ifvsc
\begin{prompt}
%\shellcmd{module load PerfExpert}%
\end{prompt}
\fi
\ifbrussel
\begin{prompt}
%\shellcmd{module load openmpi/1.6.5/gcc/4.8.2}%
\end{prompt}
\fi

For more info on iterative access to a compute node on \hpcname, please, have a look on the \hpcuserguide.

